{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b087ea",
   "metadata": {},
   "source": [
    "### Deep Learning Homework 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831ce81f",
   "metadata": {},
   "source": [
    "Taking inspiration from the last 2 pictures within the notebook (07-convnets.ipynb), implement a U-Net-style CNN with the following specs:\n",
    "\n",
    "1. All convolutions must use a 3 x 3 kernel and leave the spatial dimensions (i.e. height, width) of the input untouched.\n",
    "2. Downsampling in the contracting part is performed via maxpooling with a 2 x 2 kernel and stride of 2.\n",
    "3. Upsampling is operated by a deconvolution with a 2 x 2 kernel and stride of 2. The PyTorch module that implements the deconvolution is `nn.ConvTranspose2d`\n",
    "4. The final layer of the expanding part has only 1 channel \n",
    "\n",
    "* between how many classes are we discriminating?\n",
    "\n",
    "Create a network class with (at least) a `__init__` and a `forward` method. Please resort to additional structures (e.g., `nn.Module`s, private methods...) if you believe it helps readability of your code.\n",
    "\n",
    "Test, at least with random data, that the network is doing the correct tensor operations and that the output has the correct shape (e.g., use `assert`s in your code to see if the byproduct is of the expected shape).\n",
    "\n",
    "Note: the overall organization of your work can greatly improve readability and understanding of your code by others. Please consider preparing your notebook in an organized fashion so that we can better understand (and correct) your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a005972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pylab as pl\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a78bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([-0.2921, -0.1395, -0.2395,  0.0859, -0.1852, -0.0917, -0.1712, -0.1405,\n",
      "         0.2245,  0.1828], grad_fn=<AddBackward0>)]\n",
      "[tensor([-0.2921, -0.1395, -0.2395,  0.0859, -0.1852, -0.0917, -0.1712, -0.1405,\n",
      "         0.2245,  0.1828], grad_fn=<AddBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((10, ))\n",
    "a = []\n",
    "layer = nn.Linear(10, 10)\n",
    "out = layer(x)\n",
    "a.append(out)\n",
    "\n",
    "print(a)\n",
    "out = layer(out)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a9a577c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2387, -0.2231, -0.2372,  0.1754, -0.2415, -0.0832, -0.1299, -0.2551,\n",
       "         0.3153,  0.1280], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a7599bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_layers=2, maxpool=False, activation=nn.ReLU):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(activation())\n",
    "        for i in range(num_layers-1):\n",
    "            layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "            layers.append(activation())\n",
    "        \n",
    "        if maxpool:\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "             \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.layers(X)\n",
    "    \n",
    "class upsampling_block(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, num_mid_layers=2, activation=nn.ReLU):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            VGG_block(in_channels, mid_channels, num_layers=num_mid_layers, activation=activation),\n",
    "            nn.ConvTranspose2d(mid_channels, out_channels, kernel_size=2, stride=2),\n",
    "            activation()\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.layers(X)\n",
    "\n",
    "class U_net(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a Unet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, h=572, w=572, channels=3, depth=4, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Downsampling layers\n",
    "        downsampling_layers = []\n",
    "        in_channels, out_channels = channels, 64\n",
    "        for i in range(depth):\n",
    "            downsampling_layers.append(VGG_block(in_channels, out_channels))\n",
    "            in_channels = out_channels\n",
    "            out_channels *= 2\n",
    "        \n",
    "        self.downsampling_layers = nn.Sequential(*downsampling_layers)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Deepest layer\n",
    "        mid_channels = out_channels\n",
    "        out_channels = in_channels\n",
    "        self.deep_layer = upsampling_block(in_channels, mid_channels, out_channels)\n",
    "        \n",
    "        # Upsampling layers\n",
    "        upsampling_layers = []\n",
    "        in_channels, mid_channels, out_channels = mid_channels, out_channels, out_channels//2\n",
    "        for i in range(depth-1):\n",
    "            upsampling_layers.append(upsampling_block(in_channels, mid_channels, out_channels))\n",
    "            in_channels = in_channels//2\n",
    "            mid_channels = mid_channels//2\n",
    "            out_channels = out_channels//2\n",
    "            \n",
    "        self.upsampling_layers = nn.Sequential(*upsampling_layers)\n",
    "        \n",
    "        # Clasifier or last layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            VGG_block(in_channels, mid_channels),\n",
    "            nn.Conv2d(mid_channels, num_classes, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):        \n",
    "        skips = []\n",
    "        out = X\n",
    "        for layer in self.downsampling_layers:\n",
    "            out = layer(out)\n",
    "            skips.append(out)\n",
    "            out = self.maxpool(out)\n",
    "        \n",
    "        out = self.deep_layer(out)\n",
    "            \n",
    "        for i, layer in enumerate(self.upsampling_layers, start=1):\n",
    "            print(skips[-i].size())\n",
    "            out = torch.cat((skips[-i], out), dim=1)\n",
    "            out = layer(out)\n",
    "        \n",
    "        print(skips[0].size())\n",
    "        out = torch.cat((skips[0], out), dim=1)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1d14872c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 8, 8])\n",
      "torch.Size([4, 256, 16, 16])\n",
      "torch.Size([4, 128, 32, 32])\n",
      "torch.Size([4, 64, 64, 64])\n",
      "torch.Size([4, 10, 64, 64])\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "├─Sequential: 1-1                             --\n",
      "|    └─VGG_block: 2-1                         --\n",
      "|    |    └─Sequential: 3-1                   38,720\n",
      "|    └─VGG_block: 2-2                         --\n",
      "|    |    └─Sequential: 3-2                   221,440\n",
      "|    └─VGG_block: 2-3                         --\n",
      "|    |    └─Sequential: 3-3                   885,248\n",
      "|    └─VGG_block: 2-4                         --\n",
      "|    |    └─Sequential: 3-4                   3,539,968\n",
      "├─MaxPool2d: 1-2                              --\n",
      "├─upsampling_block: 1-3                       --\n",
      "|    └─Sequential: 2-5                        --\n",
      "|    |    └─VGG_block: 3-5                    14,157,824\n",
      "|    |    └─ConvTranspose2d: 3-6              2,097,664\n",
      "|    |    └─ReLU: 3-7                         --\n",
      "├─Sequential: 1-4                             --\n",
      "|    └─upsampling_block: 2-6                  --\n",
      "|    |    └─Sequential: 3-8                   7,603,456\n",
      "|    └─upsampling_block: 2-7                  --\n",
      "|    |    └─Sequential: 3-9                   1,901,184\n",
      "|    └─upsampling_block: 2-8                  --\n",
      "|    |    └─Sequential: 3-10                  475,456\n",
      "├─Sequential: 1-5                             --\n",
      "|    └─VGG_block: 2-9                         --\n",
      "|    |    └─Sequential: 3-11                  110,720\n",
      "|    └─Conv2d: 2-10                           650\n",
      "======================================================================\n",
      "Total params: 31,032,330\n",
      "Trainable params: 31,032,330\n",
      "Non-trainable params: 0\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "U_net(\n",
       "  (downsampling_layers): Sequential(\n",
       "    (0): VGG_block(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): VGG_block(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): VGG_block(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (3): VGG_block(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (deep_layer): upsampling_block(\n",
       "    (layers): Sequential(\n",
       "      (0): VGG_block(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (upsampling_layers): Sequential(\n",
       "    (0): upsampling_block(\n",
       "      (layers): Sequential(\n",
       "        (0): VGG_block(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "            (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): upsampling_block(\n",
       "      (layers): Sequential(\n",
       "        (0): VGG_block(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): upsampling_block(\n",
       "      (layers): Sequential(\n",
       "        (0): VGG_block(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): ReLU()\n",
       "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): VGG_block(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = U_net(h=64, w=64, channels=3, depth=4, num_classes=10)\n",
    "\n",
    "x = torch.zeros((4, 3, 64, 64))\n",
    "\n",
    "print(net(x).size())\n",
    "from torchsummary import summary\n",
    "\n",
    "_=summary(U_net())\n",
    "U_net()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
