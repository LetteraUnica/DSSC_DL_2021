{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abef5018",
   "metadata": {},
   "source": [
    "### Deep Learning Homework 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15128d9b",
   "metadata": {},
   "source": [
    "Taking inspiration from the last 2 pictures within the notebook (07-convnets.ipynb), implement a U-Net-style CNN with the following specs:\n",
    "\n",
    "1. All convolutions must use a 3 x 3 kernel and leave the spatial dimensions (i.e. height, width) of the input untouched.\n",
    "2. Downsampling in the contracting part is performed via maxpooling with a 2 x 2 kernel and stride of 2.\n",
    "3. Upsampling is operated by a deconvolution with a 2 x 2 kernel and stride of 2. The PyTorch module that implements the deconvolution is `nn.ConvTranspose2d`\n",
    "4. The final layer of the expanding part has only 1 channel \n",
    "\n",
    "* between how many classes are we discriminating?\n",
    "\n",
    "Create a network class with (at least) a `__init__` and a `forward` method. Please resort to additional structures (e.g., `nn.Module`s, private methods...) if you believe it helps readability of your code.\n",
    "\n",
    "Test, at least with random data, that the network is doing the correct tensor operations and that the output has the correct shape (e.g., use `assert`s in your code to see if the byproduct is of the expected shape).\n",
    "\n",
    "Note: the overall organization of your work can greatly improve readability and understanding of your code by others. Please consider preparing your notebook in an organized fashion so that we can better understand (and correct) your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a5f042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pylab as pl\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc6a7010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 648, 400])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros((1, 3, 324, 200))\n",
    "\n",
    "nn.ConvTranspose2d(3, 3, kernel_size=2, stride=2)(x).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af02f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model\n",
    "class U_net(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a Unet\n",
    "    \"\"\"\n",
    "    \n",
    "    def VGG_block(self, in_channels, out_channels, downsample=False, return_raw=False):\n",
    "        new_layers = []\n",
    "        new_layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        new_layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        if downsample:\n",
    "            new_layers.append(nn.MaxPool2d(2))\n",
    "            \n",
    "        if return_raw:\n",
    "            return new_layers\n",
    "        \n",
    "        return nn.Sequential(*new_layers)\n",
    "    \n",
    "    def upsampling_block(self, in_channels, out_channels, return_raw=False):\n",
    "        new_layers = self.VGG_block(in_channels, out_channels, return_raw=True)\n",
    "        new_layers.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2))\n",
    "        \n",
    "        if return_raw:\n",
    "            return new_layers\n",
    "        \n",
    "        return nn.Sequential(*new_layers)\n",
    "            \n",
    "        \n",
    "    def __init__(self, h=572, w=572, channels=3, depth=4, n_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Downsampling layers\n",
    "        self.downsampling_layers = []\n",
    "        in_channels, out_channels = channels, 64\n",
    "        for i in range(depth):\n",
    "            self.downsampling_layers.append(self.VGG_block(in_channels, out_channels))\n",
    "            in_channels = out_channels\n",
    "            out_channels *= 2\n",
    "        \n",
    "        # Deepest layer\n",
    "        self.deep_layer = self.VGG_block(in_channels, out_channels)\n",
    "        \n",
    "        # Upsampling layers\n",
    "        self.upsampling_layers = []\n",
    "        out_channels, in_channels = in_channels, out_channels\n",
    "        for i in range(depth):\n",
    "            self.upsampling_layers.append(self.upsampling_block(in_channels, out_channels))\n",
    "            in_channels = out_channels\n",
    "            out_channels = out_channels // 2\n",
    "\n",
    "    def forward(self, X):        \n",
    "        return self.layers(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
